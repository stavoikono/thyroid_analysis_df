---
title: "Thyroid Dataset Analysis"
author: "Stavros Oikonomou"
date: "3/27/2022"
output: 
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: 72
---



```{r loading libraries, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("dplyr","data.table","ggplot2","missForest", "MLDataR","tidymodels", "plotly",
              "skimr","themis","stacks","doParallel","knitr","GGally","naniar","tidyverse")

ipak(packages)
```

### Loading the dataset

For this analysis we are planning to use the **Thyroid disease prediction** from `MLDataR` package. It is a supervised machine learning classification data set to allow for the prediction of thyroid disease utilizing historic patient records.

```{r loading dataset, message=FALSE, warning=FALSE}
df_raw <- MLDataR::thyroid_disease
```
 

The **Thyroid disease prediction** dataset has:

- `r nrow(df_raw)` entries and
- `r ncol(df_raw)` variables


Let's see also the structure of our dataset

```{r df structure}
glimpse(df_raw)
```

### Data preproccessing 

Removing the binary variables about the different measurements because we are planning to use the numeric measurements and for that reason these binaries variables doesn't give us any extra information.

```{r}
df <- df_raw %>%
  select(-TSH_measured,-T3_measured,-T4_measured,-thyrox_util_rate_T4U_measured,
         -FTI_measured,-ref_src) %>%
  mutate_at(vars(patient_gender:psych_condition), 
            function(x) as.factor(as.character(x))) %>%
  mutate(Thyroid_Class = factor(ThryroidClass),
         patient_gender = factor(case_when(patient_gender==1~"Female",
                                               patient_gender==0~"Male",
                                               TRUE~NA_character_))) %>%
  select(-ThryroidClass)
```

### Data Summary

```{r}
skim(df)
```

We have an strange entry for patient_age. So we are going to exclude
extreme age values that doesn't make any sense. We have one patient with
age being 455.

We have also some extreme values for TSH, T4 and FTI but these values
are possible after checking online, so we gonna keep them. The strange
thing in these values is that all recorded for patients negative in
Thyroid issues.

```{r}
df %>% filter(patient_age>100) %>% count(patient_age)

df <- df %>% filter(patient_age <= 100)
```
### EDA

```{r}
ggplotly(
ggplot(df, aes(x=Thyroid_Class, fill=Thyroid_Class)) + geom_bar() + theme_bw() +
  xlab("Theroid Class") + ggtitle("Thyroid Class distribution"))
```

## Missing values plot

Now let's check the missing values and the patterns of missingness.

```{r, warning=FALSE, message=FALSE, fig.align='center',fig.width=8, fig.height=8}
df %>% gg_miss_upset()
```

## Correlation and descriptive plot

```{r corr plot, message=FALSE, warning=FALSE,fig.width=10, fig.height= 10}
df %>% select(which(sapply(.,class)=="numeric"),Thyroid_Class,patient_age,patient_gender) %>%
  ggpairs(aes(colour = Thyroid_Class, alpha = 0.7),
          lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.1)))
```

## Splitting the dataset

```{r}
set.seed(1234)
df_split <- initial_split(data = df,prop = 0.8 ,strata = Thyroid_Class)

df_train <- training(df_split)
df_test <- testing(df_split)
```

## Recipes for data preproccessing

We gonna use `step_*` functions from `recipe` library for data
preproccessing.

-   `step_impute_knn()` for imputing the missing data using k nearest neighbor
    models with default settings. All predictors are going to be used for the knn model

-   `step_downsample()` We have an imbalanced dataset so we gonna use
    downsample to train the model

-   `step_nzv()` for removing variables with variance close to zero

-   `step_log()` for transforming the TSH_reading to normal distribution.
    Even we are not using a model that has the normal distribution
    assumptions, I decide to logtransform because of few outlier values

-   `step_normalize()` scale and center all numerical values

-   `step_dummy()` here is one difference with `caret` or `R based` ML
    models who automatically do that step, but because we are train our
    model with `Tidymodels` we need to do that step for all nominal
    variables

This recipe also gonna be applied for our test set, but instead of using
the `juice()` function we are going to use the `bake()` function. The
`juice()` function use the same recipe but applies only for the data we
set in our recipe. If we want to use a recipe to a new dataset we have
to use the `bake()` function.

```{r, eval=FALSE}
train_balanced <- 
  recipe(Thyroid_Class ~ . ,data = df_train) %>%
  #step_impute_bag(all_predictors()) %>%
  step_nzv(all_predictors(),freq_cut = 99/1) %>%
  step_log(TSH_reading) %>%
  step_normalize(all_numeric()) %>%
  step_downsample(Thyroid_Class, skip = TRUE) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  prep()
  
# train_ds <- juice(train_recipe)
# 
# test_ds <- bake(object = train_recipe,new_data = df_test)
```




```{r}
# for no downsample
train_recipe_imb <- 
  recipe(Thyroid_Class ~ . ,data = df_train) %>%
  step_impute_knn(all_predictors()) %>%
  step_nzv(all_predictors(),freq_cut = 99/1) %>%
  #step_novel(all_nominal_predictors()) %>%
  step_log(TSH_reading) %>%
  step_normalize(all_numeric()) %>%
  step_dummy(all_nominal(), -all_outcomes()) 
```

Setting the k-fold cross validation for k=10 stratified by Thyroid class.

Setting the metrics for training the Random forest algorithm. We are gonna use the `yardstick` package for setting the metrics:

+ Accuracy

+ Sensitivity

+ Specificity

+ Mean log loss

```{r}
set.seed(1234)

train_fold <- vfold_cv(df_train, v=10, strata = Thyroid_Class)

thyroid_metrics <- metric_set(mn_log_loss, accuracy, sensitivity, specificity)
```

Setting the engine for the model. Planning to tune the `mtry` and `min_n` parameters.

```{r, message=FALSE, warning=FALSE}
library(baguette)
library(ranger)

tune_spec <- 
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = 100) %>%
  set_engine("ranger") %>%
  set_mode("classification")

ctrl <- control_resamples(save_pred = TRUE)
```

Creating the workflow using the recipe and the engine we set up in previous steps.

```{r}
imb_wf <- workflow() %>%
  add_recipe(train_recipe_imb) %>%
  add_model(tune_spec)

```

We can have three types of fitting:
+ plain fit with `fit()` function
+ fitting with resample using the `fit_resamples()` function
+ if we want to tune the hyperparameters `tune_grid()`

Parallel proccessing gonna be used for training the model faster.

```{r tune grid, message=FALSE, warning=FALSE}

set.seed(345)

doParallel::registerDoParallel()

tune_res <- 
  tune::tune_grid(object = imb_wf,
          resamples = train_fold,
          grid=20,
          control= ctrl)
```

printing the metrics fo the different mtry and min_n combinations 

`r kable(tune_res %>% collect_metrics(), "pipe")`


Printing the AUROC for the different models trained and tested in each fold

```{r}
tune_res %>% 
  collect_predictions() %>%
  group_by(id) %>%
  roc_curve(Thyroid_Class, .pred_negative) %>%
  autoplot
```

Plotting the how mtry and min_n affect the AUC

```{r}
tune_res %>% collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC") + theme_bw()
```

Selecting the best model and fitting one more time to create the final model.

```{r}
best_auc <- select_best(tune_res, "roc_auc")

final_model <- finalize_model(tune_spec,best_auc)
```

Printing the most important variable by descenting order.

```{r, warning=FALSE, message=FALSE}
library(vip)

train_prep <- prep(train_recipe_imb)


final_model %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(Thyroid_Class~. , data= juice(train_prep)) %>%
  vip(geom = "point")
```

Now we gonna fit the final model to the test set.

We can do that with `tidymodels` by fitting the model to the initial split object.

```{r}
final_res <- imb_wf %>%
  finalize_workflow(select_best(tune_res, "roc_auc")) %>%
  last_fit(df_split)
```

`r kable(final_res %>% collect_metrics(), "pipe")`

Confusion matrix

```{r}
collect_predictions(final_res) %>% conf_mat(Thyroid_Class, .pred_class)
```





